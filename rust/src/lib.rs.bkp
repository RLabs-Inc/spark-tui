//! SparkTUI Engine - Rust side of the hybrid TUI framework.
//!
//! This cdylib receives a SharedArrayBuffer pointer from TypeScript (via Bun FFI),
//! reads layout properties, runs Taffy flexbox computation, builds the framebuffer,
//! diff-renders to the terminal, and handles all input.
//!
//! # Architecture
//!
//! ```text
//! TypeScript (Developer API)                    Rust (The Engine)
//! ─────────────────────────                    ─────────────────
//! Developer writes components                   Rust OWNS everything:
//!   → box({ fg: red })                            stdin → state → layout →
//!   → text({ content: "hi" })                     framebuffer → diff → terminal
//!        │                                              │
//!        │ writes props                                 │ writes events
//!        ▼                                              ▼
//!   ┌────────────────────────────────────────────────────┐
//!   │            SharedArrayBuffer (AoS ~26MB)            │
//!   │  256 bytes per node (contiguous, cache-friendly)    │
//!   │  Layout, Visual, Text, Interaction, Output          │
//!   │  Event Ring Buffer (256 events)                     │
//!   └────────────────────────────────────────────────────┘
//! ```

pub mod shared_buffer_aos;
pub mod shared_buffer;
pub mod utils;
pub mod layout;
pub mod renderer;
pub mod framebuffer;
pub mod input;
pub mod pipeline;

#[cfg(test)]
mod bench_layout;

use shared_buffer_aos::AoSBuffer;
use std::sync::OnceLock;

// =============================================================================
// GLOBAL STATE
// =============================================================================

/// The shared buffer (AoS layout), initialized once via FFI.
static BUFFER: OnceLock<AoSBuffer> = OnceLock::new();

fn get_buffer() -> &'static AoSBuffer {
    BUFFER.get().expect("AoSBuffer not initialized - call spark_init() first")
}

/// Global engine handle.
static ENGINE: OnceLock<pipeline::Engine> = OnceLock::new();

// =============================================================================
// FFI EXPORTS
// =============================================================================

/// Initialize the engine with a pointer to the SharedArrayBuffer.
///
/// This:
/// 1. Creates the AoSBuffer view (256 bytes per node, cache-friendly)
/// 2. Starts the engine thread (terminal setup, stdin, reactive pipeline)
///
/// Called once from TypeScript:
/// ```typescript
/// const lib = dlopen("./spark_tui_engine.dylib", { spark_init: { args: ["ptr", "u32"], returns: "u32" } })
/// lib.symbols.spark_init(buffer.ptr, buffer.byteLength)
/// ```
#[unsafe(no_mangle)]
pub extern "C" fn spark_init(ptr: *mut u8, len: u32) -> u32 {
    let buf = unsafe { AoSBuffer::from_raw(ptr, len as usize) };
    match BUFFER.set(buf) {
        Ok(_) => {
            eprintln!("[spark-engine] Initialized with {}KB AoS buffer ({} max nodes)",
                len / 1024, shared_buffer_aos::MAX_NODES);

            // Start the engine
            let buf = get_buffer();
            match pipeline::Engine::start(buf) {
                Ok(engine) => {
                    let _ = ENGINE.set(engine);
                    0 // success
                }
                Err(e) => {
                    eprintln!("[spark-engine] Failed to start engine: {}", e);
                    2 // engine start failed
                }
            }
        }
        Err(_) => {
            eprintln!("[spark-engine] Already initialized!");
            1 // already init
        }
    }
}

/// Compute layout using Taffy's low-level trait API and write results to the output section.
///
/// Uses AoS buffer with cache-friendly 256-byte node stride.
/// NodeId IS the component index — zero translation, zero double-bookkeeping.
///
/// Returns the number of nodes laid out.
#[unsafe(no_mangle)]
pub extern "C" fn spark_compute_layout() -> u32 {
    let buf = get_buffer();
    layout::compute_layout(buf)
}

/// Compute framebuffer from AoSBuffer data and render to terminal.
///
/// Called by TS after writing props to trigger a render.
/// In the full reactive pipeline, this happens automatically via the engine thread.
#[unsafe(no_mangle)]
pub extern "C" fn spark_render() -> u32 {
    let buf = get_buffer();
    let tw = buf.terminal_width() as u16;
    let th = buf.terminal_height() as u16;

    // Layout
    layout::compute_layout(buf);

    // Framebuffer
    let (fb, _hit_regions) = framebuffer::compute_framebuffer(buf, tw, th);

    // We can't keep a renderer in a static easily, so just report buffer size
    (fb.width() as u32) * (fb.height() as u32)
}

/// Get the total shared buffer size needed (for TypeScript to allocate).
#[unsafe(no_mangle)]
pub extern "C" fn spark_buffer_size() -> u32 {
    shared_buffer_aos::TOTAL_BUFFER_SIZE as u32
}

/// Wake the engine (TS calls this after writing props to SharedBuffer).
#[unsafe(no_mangle)]
pub extern "C" fn spark_wake() {
    let buf = get_buffer();
    buf.set_wake_flag();
}

/// Stop the engine and clean up.
#[unsafe(no_mangle)]
pub extern "C" fn spark_cleanup() {
    if let Some(engine) = ENGINE.get() {
        engine.stop();
    }
}

// =============================================================================
// TEST: Adaptive spin-wait (the REAL engine mechanism)
// =============================================================================

/// Test the ACTUAL adaptive spin-wait mechanism used by the engine.
///
/// Buffer layout (24 bytes):
///   [0]:  u32 — wake flag (JS stores 1)
///   [1]:  u32 — result (0=waiting, 1=detected)
///   [2]:  u32 — latency in microseconds
///   [3]:  u32 — phase when detected (1=spin, 2=yield, 3=sleep)
///   [4]:  u32 — iteration count when detected
///   [5]:  u32 — reserved
#[unsafe(no_mangle)]
pub extern "C" fn spark_test_adaptive_wake(ptr: *mut u8) -> u32 {
    if ptr.is_null() {
        return 1;
    }

    let addr = ptr as usize;

    std::thread::Builder::new()
        .name("adaptive-wake-test".into())
        .spawn(move || {
            use std::sync::atomic::{AtomicU32, Ordering};
            use std::time::Duration;

            let flag = unsafe { &*(addr as *const AtomicU32) };
            let result = unsafe { &*((addr + 4) as *const AtomicU32) };
            let latency = unsafe { &*((addr + 8) as *const AtomicU32) };
            let phase_out = unsafe { &*((addr + 12) as *const AtomicU32) };
            let iter_out = unsafe { &*((addr + 16) as *const AtomicU32) };

            let start = std::time::Instant::now();
            let mut idle_count: u32 = 0;

            loop {
                if flag.load(Ordering::Acquire) != 0 {
                    let elapsed = start.elapsed().as_micros() as u32;
                    let phase = if idle_count < 64 {
                        1
                    } else if idle_count < 256 {
                        2
                    } else {
                        3
                    };

                    result.store(1, Ordering::Release);
                    latency.store(elapsed, Ordering::Release);
                    phase_out.store(phase, Ordering::Release);
                    iter_out.store(idle_count, Ordering::Release);
                    return;
                }

                idle_count = idle_count.saturating_add(1);
                if idle_count < 64 {
                    std::hint::spin_loop();
                } else if idle_count < 256 {
                    std::thread::yield_now();
                } else {
                    std::thread::sleep(Duration::from_micros(50));
                }
            }
        })
        .ok();

    0
}

// =============================================================================
// TEST: Cross-language atomic wake
// =============================================================================

/// Test if Atomics.notify() from JS wakes atomic_wait::wait() in Rust.
///
/// Uses the `atomic-wait` crate which on macOS uses the same libc++ functions
/// behind C++20's std::atomic_wait/notify — should be ABI-compatible with
/// JavaScriptCore's Atomics.notify().
///
/// Buffer layout (16 bytes, must be SharedArrayBuffer):
///   [0..4]:   u32 — flag (JS stores 1 + Atomics.notify)
///   [4..8]:   u32 — result (0=waiting, 1=woken)
///   [8..12]:  u32 — latency in microseconds
///   [12..16]: u32 — reserved
///
/// mode: 0 = atomic_wait::wait, 1 = spin loop (control), 2 = wait_on_address (os_sync_*), 3 = ecmascript_futex
#[unsafe(no_mangle)]
pub extern "C" fn spark_test_atomic_wait(ptr: *mut u8, mode: u32) -> u32 {
    if ptr.is_null() {
        return 1;
    }

    let addr = ptr as usize;

    std::thread::Builder::new()
        .name("atomic-wait-test".into())
        .spawn(move || {
            use std::sync::atomic::{AtomicU32, Ordering};

            let flag = unsafe { &*(addr as *const AtomicU32) };
            let result = unsafe { &*((addr + 4) as *const AtomicU32) };
            let latency = unsafe { &*((addr + 8) as *const AtomicU32) };

            let start = std::time::Instant::now();

            match mode {
                // Mode 0: atomic_wait::wait — THE critical test
                // macOS: libc++ atomic_wait (same ABI as C++20 std::atomic_wait)
                // Linux: futex(FUTEX_WAIT)
                0 => {
                    atomic_wait::wait(flag, 0);
                    let elapsed = start.elapsed().as_micros() as u32;
                    result.store(1, Ordering::Release);
                    latency.store(elapsed, Ordering::Release);
                    eprintln!("[rust] atomic_wait::wait woke after {}μs", elapsed);
                }
                // Mode 1: Spin on atomic load (control — always works)
                1 => {
                    loop {
                        if flag.load(Ordering::Acquire) != 0 {
                            break;
                        }
                        std::hint::spin_loop();
                    }
                    let elapsed = start.elapsed().as_micros() as u32;
                    result.store(1, Ordering::Release);
                    latency.store(elapsed, Ordering::Release);
                    eprintln!("[rust] spin detected change in {}μs", elapsed);
                }
                // Mode 2: wait_on_address — uses os_sync_wait_on_address on macOS 14.4+
                2 => {
                    use wait_on_address::AtomicWait;
                    flag.wait(0);
                    let elapsed = start.elapsed().as_micros() as u32;
                    result.store(1, Ordering::Release);
                    latency.store(elapsed, Ordering::Release);
                    eprintln!("[rust] wait_on_address woke after {}μs", elapsed);
                }
                // Mode 3: ecmascript_futex — ECMAScript memory model futex
                // macOS: os_sync_wait_on_address via Racy<u32> (ECMAScript-compatible)
                3 => {
                    use std::ptr::NonNull;
                    use ecmascript_atomics::RacyMemory;
                    use ecmascript_futex::ECMAScriptAtomicWait;

                    let u32_ptr = NonNull::new(addr as *mut u32).unwrap();
                    let slice_ptr = NonNull::slice_from_raw_parts(u32_ptr, 4);
                    let racy_mem = unsafe { RacyMemory::<u32>::enter_slice(slice_ptr) };

                    {
                        let slice = racy_mem.as_slice();
                        let racy_flag = slice.get(0).unwrap();
                        let racy_result = slice.get(1).unwrap();
                        let racy_latency = slice.get(2).unwrap();

                        // Wait while value == 0 (block until JS stores 1)
                        let wait_result = racy_flag.wait(0);
                        let elapsed = start.elapsed().as_micros() as u32;

                        racy_result.store(1, ecmascript_atomics::Ordering::SeqCst);
                        racy_latency.store(elapsed, ecmascript_atomics::Ordering::SeqCst);
                        eprintln!("[rust] ecmascript_futex woke after {}μs (wait result: {:?})", elapsed, wait_result);
                    }

                    // Don't exit — JS owns this memory. Just forget the handle.
                    std::mem::forget(racy_mem);
                }
                _ => {
                    result.store(3, Ordering::Release);
                }
            }
        })
        .ok();

    0
}

